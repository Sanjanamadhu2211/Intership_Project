**Real-Time Sign Language Recognition**

Objective: Convert hand gestures to text in real-time.


**Dataset used**: https://www.kaggle.com/datasets/grassknoted/asl-alphabet?select=asl_alphabet_train 

**Steps Remaining**: 

-> Training the cnn properly and getting its prediction

-> Testing main.py 

-> Improving the code presentation and reducing the complexity  


Alternate Datasets

Sataset-: https://www.kaggle.com/datasets/ayuraj/asl-dataset

NOTE: Try to run the main.py with the model that i sent, named ANOTHER_SOME_CHANGES_NEW_MODEL.keras, u can see the result. When you r showing this project to the reviewer, try to not use T hand sign because it is has the same type of sign as S for the model. When u want to predict the hand sign, try to hold the for at least 4-5 seconds and change angles slightly.First, try to predict all the alphabets one by one by changing hand angles, then u will know how model is predicting the alphabet. Like u will get the idea when we keep like this(hand posture),how my model predicts correctly.
